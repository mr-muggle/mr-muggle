(window.webpackJsonp=window.webpackJsonp||[]).push([[22],{672:function(_,v,o){"use strict";o.r(v);var l=o(74),n=Object(l.a)({},(function(){var _=this,v=_._self._c;return v("ContentSlotsDistributor",{attrs:{"slot-key":_.$parent.slotKey}},[v("h2",{attrs:{id:"事务的定义"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#事务的定义"}},[_._v("#")]),_._v(" 事务的定义")]),_._v(" "),v("p",[_._v("事务就是一组原子性的 SQL 查询，或者说一个独立的工作单元。如果数据库引擎能够成功地对数据库应用该组查询的全部语句，那么就执行该组查询。如果其中有任何一条语句因为崩溃或其他原因无法执行，那么所有的语句都不会执行。也就是说，事务内的语句，要么全部执行成功，要么全部执行失败。")]),_._v(" "),v("p",[_._v("一个良好的事务处理系统，必须具备 ACID 特性：")]),_._v(" "),v("ul",[v("li",[_._v("atomicity（原子性） ：要么全执行，要么全都不执行；")]),_._v(" "),v("li",[_._v("consistency（一致性）：在事务开始和完成时，数据都必须保持一致状态；")]),_._v(" "),v("li",[_._v("isolation（隔离性） ：事务处理过程中的中间状态对外部是不可见的；")]),_._v(" "),v("li",[_._v("durability（持久性） ：事务完成之后，它对于数据的修改是永久性的。")])]),_._v(" "),v("p",[_._v("InnoDB 采用 redo log 机制来保证事务更新的一致性和持久性。")]),_._v(" "),v("h2",{attrs:{id:"redo-log-重做日志"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#redo-log-重做日志"}},[_._v("#")]),_._v(" Redo log（重做日志）")]),_._v(" "),v("p",[_._v("Redo log 称为重做日志，用于记录事务操作变化，记录的是数据被修改之后的值。")]),_._v(" "),v("p",[_._v("Redo log 由两部分组成：")]),_._v(" "),v("ul",[v("li",[_._v("内存中的重做日志缓冲（redo log buffer）")]),_._v(" "),v("li",[_._v("重做日志文件（redo log file）")])]),_._v(" "),v("p",[_._v("每次数据更新会先更新 redo log buffer，然后根据 "),v("code",[_._v("innodb_flush_log_at_trx_commit")]),_._v(" 来控制 "),v("code",[_._v("redo log buffer")]),_._v("更新到 redo log file 的时机。"),v("code",[_._v("innodb_flush_log_at_trx_commit")]),_._v(" 有三个值可选：")]),_._v(" "),v("p",[_._v("0：事务提交时，每秒触发一次 "),v("code",[_._v("redo log buffer")]),_._v(" 写磁盘操作，并调用操作系统 fsync 刷新 IO 缓存。")]),_._v(" "),v("p",[_._v("1：事务提交时，InnoDB 立即将缓存中的 redo 日志写到日志文件中，并调用操作系统 fsync 刷新 IO 缓存；")]),_._v(" "),v("p",[_._v("2：事务提交时，InnoDB 立即将缓存中的 redo 日志写到日志文件中，但不是马上调用 fsync 刷新 IO 缓存，而是每秒只做一次磁盘 IO 缓存刷新操作。")]),_._v(" "),v("p",[v("code",[_._v("innodb_flush_log_at_trx_commit")]),_._v(" 参数的默认值是 1，也就是每个事务提交的时候都会从 "),v("code",[_._v("log buffer")]),_._v("写更新记录到日志文件，而且会刷新磁盘缓存，这完全满足事务持久化的要求，是最安全的，但是这样会有比较大的性能损失。")]),_._v(" "),v("p",[_._v("将参数设置为 0 时，如果数据库崩溃，最后 1秒钟的 redo log 可能会由于未及时写入磁盘文件而丢失，这种方式尽管效率最高，但是最不安全。")]),_._v(" "),v("p",[_._v("将参数设置为 2 时，如果数据库崩溃，由于已经执行了重做日志写入磁盘的操作，只是没有做磁盘 IO 刷新操作，因此，只要不发生操作系统奔溃，数据就不会丢失，这种方式是对性能和安全的一种折中处理。")]),_._v(" "),v("h2",{attrs:{id:"bin-log-二进制日志"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#bin-log-二进制日志"}},[_._v("#")]),_._v(" Bin log(二进制日志)")]),_._v(" "),v("p",[_._v("二进制日志（binlog）记录了所有的 DDL（数据定义语句）和 DML（数据操纵语句），但是不包括 select 和 show 这类操作。Binlog 有以下几个作用：")]),_._v(" "),v("ul",[v("li",[_._v("恢复：数据恢复时可以使用二进制日志")]),_._v(" "),v("li",[_._v("复制：通过传输二进制日志到从库，然后进行恢复，以实现主从同步")]),_._v(" "),v("li",[_._v("审计：可以通过二进制日志进行审计数据的变更操作")])]),_._v(" "),v("p",[_._v("可以通过参数 sync_binlog 来控制累积多少个事务后才将二进制日志 fsync 到磁盘。")]),_._v(" "),v("ul",[v("li",[_._v("sync_binlog=0，表示每次提交事务都只write，不fsync")]),_._v(" "),v("li",[_._v("sync_binlog=1，表示每次提交事务都会执行fsync")]),_._v(" "),v("li",[_._v("sync_binlog=N(N>1)，表示每次提交事务都write，累积N个事务后才fsync")])]),_._v(" "),v("p",[_._v("比如要加快写入数据的速度或者机器磁盘 IO 瓶颈时，可以将 sync_binlog 设置成大于 1 的值，"),v("strong",[_._v("但是如果设置为 N(N>1)时，如果数据库崩溃，可能会丢失最近 N 个事务的 binlog。")])]),_._v(" "),v("p",[_._v("只要 "),v("code",[_._v("innodb_flush_log_at_trx_commit")]),_._v(" 和 "),v("code",[_._v("sync_binlog")]),_._v(" 都为 1（通常称为：双一），就能确保 MySQL 机器断电重启后，数据不丢失。")]),_._v(" "),v("p",[_._v("因此建议在比较重要的库，比如涉及到钱的库，设置为双一，而你的测试环境或者正式业务不那么重要的库（比如日志库）可以将 "),v("code",[_._v("innodb_flush_log_at_trx_commit")]),_._v(" 设置为0，"),v("code",[_._v("sync_binlog")]),_._v("设置成大于100 的数值，提高更新效率。")]),_._v(" "),v("h2",{attrs:{id:"undo-log-逻辑日志"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#undo-log-逻辑日志"}},[_._v("#")]),_._v(" undo log（逻辑日志）")]),_._v(" "),v("p",[v("code",[_._v("redo log")]),_._v("，它记录了事务操作变化。但是事务有时是需要回滚的，这时，undo log 就发挥了作用。undo log 是逻辑日志，将数据库逻辑地恢复到原来的样子，所有修改都被逻辑地取消了。")]),_._v(" "),v("p",[_._v("也就是如果是 insert 操作，其对应的回滚操作就是 delete；")]),_._v(" "),v("p",[_._v("如果是 delete，则对应的回滚操作是 insert；")]),_._v(" "),v("p",[_._v("如果是 update，则对应的回滚操作是一个反向的 update 操作。")]),_._v(" "),v("p",[_._v("除了回滚操作，"),v("code",[_._v("undo log")]),_._v(" 的另一个作用是 MVCC，InnoDB 存储引擎中 MVCC 的实现是通过 undo 来完成的。当用户读取一行记录时，若该记录已经被其它事务占用，当前事务可以通过 undo log 读取之前的行版本信息，以此实现非锁定读取。")]),_._v(" "),v("h2",{attrs:{id:"养成好的事务习惯"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#养成好的事务习惯"}},[_._v("#")]),_._v(" 养成好的事务习惯")]),_._v(" "),v("ul",[v("li",[v("p",[_._v("循环写入的情况，如果循环次数不是太多，建议在循环前开启一个事务，循环结束后统一提交。")])]),_._v(" "),v("li",[v("p",[_._v("优化事务里的语句顺序，减少锁时间。根据两阶段锁，整个事务里面涉及的锁，需要等到事务提交时才会释放。因此我们在"),v("strong",[_._v("同一个事务中，可以把没锁或者锁范围小的语句放在事务前面执行，而锁定范围大的语句放在后面执行。")])])]),_._v(" "),v("li",[v("p",[_._v("关注不同事务访问资源的顺序。死锁原因中有两条就跟不同事务访问资源顺序有关，我们来回顾一下：")]),_._v(" "),v("ul",[v("li",[_._v("不同线程并发访问同一张表的多行数据，未按顺序访问导致死锁。")]),_._v(" "),v("li",[_._v("不同线程并发访问多个表时，未按顺序访问导致死锁。")])]),_._v(" "),v("p",[_._v("如果不关注并发访问的不同事务中访问资源的顺序，就会增大出现死锁的概率。")]),_._v(" "),v("p",[_._v("因此，为了降低死锁，我们需要去关注不同事务访问资源的顺序。")])]),_._v(" "),v("li",[v("p",[_._v("创建事务之前，关注事务隔离级别。")])]),_._v(" "),v("li",[v("p",[_._v("不在事务中混合使用存储引擎。")])])])])}),[],!1,null,null,null);v.default=n.exports}}]);